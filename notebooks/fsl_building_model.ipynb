{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceSegLite: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset Loading**\n",
    "\n",
    "\n",
    "First, we define utils function to be able to load the HuggingFace datasets correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_format(file_path):\n",
    "  \"\"\"\n",
    "  Loads a file in YOLO format.\n",
    "  \n",
    "  Args:\n",
    "    - file_path: path to the file to load.\n",
    "    \n",
    "  Returns:\n",
    "    - objects: list of objects in the image. Each object is represented as a\n",
    "      tuple of (class_index, (x1, y1, ..., xn, yn)).\n",
    "  \"\"\"\n",
    "  with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "  objects = []\n",
    "  for line in lines:\n",
    "    data = line.strip().split()\n",
    "    class_index = int(data[0])\n",
    "    coordinates = list(map(float, data[1:]))\n",
    "    objects.append((class_index, coordinates))\n",
    "\n",
    "  return objects\n",
    "\n",
    "def found_directory(file_path, folders):\n",
    "    \"\"\"\n",
    "    Finds the directory in which the file is located.\n",
    "\n",
    "    Args:\n",
    "        - file_path: path to the file to load.\n",
    "        - folders: list of folders to look into.\n",
    "    \n",
    "    Returns:\n",
    "        - folder: name of the folder in which the file is located.\n",
    "    \"\"\"\n",
    "    for i, folder in enumerate(folders):\n",
    "        file_id = file_path.split('_')[0]\n",
    "        folder_id = folder.split('--')[0]\n",
    "        if file_id == folder_id:\n",
    "            return folders[i]\n",
    "    raise ValueError(f\"Folder {folders} not found in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom torch Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FslDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.mask_folder = os.path.join(root_dir, 'masks')\n",
    "        self.mask_files = sorted(os.listdir(self.mask_folder))\n",
    "\n",
    "        self.image_folder = os.path.join(root_dir, 'images')\n",
    "        self.image_files = [os.path.join(self.image_folder, found_directory(file_path, os.listdir(self.image_folder)),\n",
    "                file_path.replace('txt', 'jpg')) for file_path in self.mask_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image\n",
    "        image = cv2.imread(self.image_files[idx])\n",
    "\n",
    "        # Get the masks\n",
    "        masks = load_yolo_format(os.path.join(self.mask_folder, self.mask_files[idx]))\n",
    "\n",
    "        sample = {'image': image, 'masks': masks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsl_dataset = FslDataset(root_dir='../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset vizualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_color(index):\n",
    "    \"\"\"\n",
    "    Generates a unique RGB color for a given class index.\n",
    "\n",
    "    Args:\n",
    "        - index: class index\n",
    "    \n",
    "    Returns:\n",
    "        - color: tuple of (R, G, B) values\n",
    "    \"\"\"\n",
    "    np.random.seed(index) # For reproducibility\n",
    "    return tuple(np.random.rand(3))\n",
    "\n",
    "def plot_image_with_mask(image, objects):\n",
    "    \"\"\"\n",
    "    Plots an image with its segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        - image_path: path to the image\n",
    "        - objects: list of objects in the image. Each object is represented as a\n",
    "          tuple of (class_index, (x1, y1, ..., xn, yn)).\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    #image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Plot the segmentation mask for each object with a unique color\n",
    "    for index, (class_index, coordinates) in enumerate(objects):\n",
    "        num_points = len(coordinates) // 2\n",
    "        mask_points = np.array(coordinates).reshape((num_points, 2))\n",
    "        mask_points *= np.array([image.shape[1], image.shape[0]])  # Convert normalized coordinates to pixels\n",
    "        mask_points = mask_points.astype(int)\n",
    "\n",
    "        # Draw a polygon for the segmentation mask\n",
    "        color = get_unique_color(index)\n",
    "        polygon = Polygon(mask_points, closed=True, edgecolor=color, facecolor='none', linewidth=2)\n",
    "        plt.gca().add_patch(polygon)\n",
    "\n",
    "        # Fill the polygon with a unique color\n",
    "        plt.fill(mask_points[:, 0], mask_points[:, 1], color=color, alpha=0.3)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"fsl_dataset/FSL_masks/19_Couple_Couple_19_12.txt\"\n",
    "image_1 = load_yolo_format(dataset_path)\n",
    "\n",
    "image_path = \"fsl_dataset/FSL_images/images/19--Couple/19_Couple_Couple_19_12.jpg\"\n",
    "\n",
    "plot_image_with_mask(image_path, image_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
